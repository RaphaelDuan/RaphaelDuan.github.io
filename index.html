<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Di Duan, Ph.D.</title>

    <meta name="author" content="Di Duan">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Di Duan
                </p>
                <p>I am a <b>Postdoctoral Fellow</b> in the <a href="https://www.ie.cuhk.edu.hk/">Department of Information Engineering</a> at The Chinese University of Hong Kong (<a href="https://www.cuhk.edu.hk/chinese/index.html">CUHK</a>), advised by Prof. <a href="https://staff.ie.cuhk.edu.hk/~glxing/">Guoliang Xing</a> (ACM Fellow, IEEE Fellow). Before join CUHK AIOT lab, I obtained my Ph.D. degree from the Department of Computer Science at City University of Hong Kong (<a href="https://www.cityu.edu.hk/">CityU</a>), supervised by Prof. <a href="https://www.weitaoxu.com/">Weitao Xu</a> (IEEE Senior Member) and co-supervised by Prof. <a href="https://www.cs.cityu.edu.hk/~jia/">Xiaohua Jia</a> (IEEE Fellow), I also work closely with Prof. <a href="https://www.cse.msu.edu/~litianx2/">Tianxing Li</a>. I received the ACM SenSys'25 Best Paper Honorable Mention Award, ACM MobileHCI'24 Honorable Mention Award, and IEEE PerCom'23 Mark Weiser Best Paper Award.
                </p>
                <p>
                  My research lies at the intersection of Mobile Sensing and Human-Computer Interaction — with a special focus on <span style="color: #E31C79">wearable and wireless sensing systems, software-hardware co-design, health and AI</span>  — to enable <span style="color: #E31C79">novel, secure, and user-friendly applications</span>.
                </p>
                <p>
                  My current research interests include:
                </p>
                <ul style="list-style-type: square; padding-left: 20px;">
                  <li> (1) Pioneering Sensing Technologies (Wearable + Wireless);</li>
                  <li> (2) Affordable, Secure, and User-friendly Sensing Applications via Software-Hardware Co-Design;</li>
                  <li> (3) Healthcare + AI for Diagnosis, Monitoring, and Intervention.</li>
                </ul>
                <p>
                  <strong>Email:</strong> duandiacademic [AT] gmail [DOT] com<br>
                  <strong>CUHK:</strong> diduan [AT] ie.cuhk [DOT] edu.hk
                </p>
                <p style="text-align:center">
                  <a href="mailto:duandiacademic@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Di Duan_CV_202507.pdf">CV</a> <span style="font-size: smaller;">(Updated: 2025-07)</span> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=BRFlCnUAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/di-duan-543065170/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/pictures/avatar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/pictures/avatar.jpg" class="hoverZoomLink"></a>
                <!-- StatCounter 计数器 -->
                <p style="text-align:center; font-size: smaller; margin-top: 10px;">
                  You are the 
                  <!-- Default Statcounter code for Personal Homepage -->
                  <script type="text/javascript">
                    var sc_project=13097429; 
                    var sc_invisible=0; 
                    var sc_security="682f0114"; 
                    var scJsHost = "https://";
                    document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
                    "statcounter.com/counter/counter.js'></"+"script>");
                    </script>
                    <noscript><div class="statcounter"><a title="Web Analytics"
                    href="https://statcounter.com/" target="_blank"><img class="statcounter"
                    src="https://c.statcounter.com/13097429/0/682f0114/0/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
                    <!-- End of Statcounter Code -->
                  th visitor.
                </p>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <ul>
                  <li>[2025/08] Glad to be invitied as a TPC member of <a href="http://ieee-icpads.org.cn/">ICPADS 2025</a>. Welcome to submit papers!</li>
                  <li>[2025/07] <span style="color: red; font-weight: bold;">News!</span> My PhD thesis has been recognized with the <span class="highlight">Outstanding Research Thesis Award</span> by CityU!</li>
                  <li>[2025/07] <span style="color: red; font-weight: bold;">News!</span> Our paper PricoEye is accepted by UIST'25 (unanimously accepted). I will showcase our live demo and deliver the paper presentation in Busan, Korea in Sep. 2025. Find me at the venue for a chat!</li>
                  <li>[2025/05] <span style="color: red; font-weight: bold;">News!</span> Our paper Argus received the <span class="highlight">Best Paper Honorable Mention Award</span> at SenSys 2025. <span style="color: red; font-weight: bold;">5 out of all submissions</span></li>
                  <li>[2025/01] Our paper Argus is accepted by SenSys'25. I will present this paper in Irvine, CA in May. 2025.</li>
                </ul>
                <details>
                  <summary>Earlier News</summary>
                  <ul>
                    <li>[2024/10] Glad to be invitied as a TPC member of <a href="https://chchi.icachi.org/24/">CHCHI (Chinese CHI) 2024</a>.</li>
                    <li>[2024/10] One co-first authored paper, Medusa3D, received the <span class="highlight">Honorable Mention Award</span> at MobileHCI 2024.</li>
                    <li>[2024/07] Glad to be invitied as a TPC member of <a href="https://attend.ieee.org/icpads/">ICPADS 2024</a>.</li>
                    <li>[2024/07] I will join the <a href="https://aiot.ie.cuhk.edu.hk">CUHK AIoT Lab</a> as a <b>Postdoctoral Fellow</b>, working directly with Prof. <a href="https://staff.ie.cuhk.edu.hk/~glxing/">Guoliang Xing</a>.</li>
                    <li>[2024/06] I'm pleased to share with everyone that I have just passed my Ph.D. defense.</li>
                    <li>[2024/04] One co-first authored paper Medusa3D is conditionally accepted (with minor revision) by MobileHCI'24.</li>
                    <li>[2024/03] I'm serving as the Publicity Chair of BobySys Workshop (MobiSys 2024). Please refer to our <a href="https://www.eventcreate.com/e/bodysys24">official website</a>. </li>
                    <li>[2024/03] Our paper F2Key is accepted by MobiSys'24. I will present this paper in Tokyo in Jun. 2024.</li>
                    <li>[2024/02] One co-authored paper RF-Egg is accepted by MobiCom'24.</li>
                    <li>[2023/10] Our paper EarSE is accepted by IMWUT/UbiComp'24. I will present this paper in Melbourne in Oct. 2024.</li>
                    <li>[2023/03] Receive Monetary Award of 300 USD from Elsevier.</li>
                    <li>[2023/03] Our paper EMGSense received the <span class="highlight">Mark Weiser Best Paper Award</span> at PerCom 2023.</li>
                  </ul>
                </details>

                <h2>Selected Honor and Awards</h2>
                <ul>
                  <li><i class="fa fa-certificate"></i> <strong>Outstanding Research Thesis Award</strong>, CityU, 2025</li>
                  <li><i class="fa fa-trophy"></i> <strong>Best Paper Honorable Mention Award</strong>, ACM SenSys, 2025</li>
                  <li><i class="fa fa-trophy"></i> <strong>Best Demo Runner-up Award, ACM SenSys</strong>, 2024</li>
                  <li><i class="fa fa-trophy"></i> <strong>Honorable Mention Award</strong>, ACM MobileHCI, 2024</li>
                  <li><i class="fa fa-trophy"></i> <strong>Mark Weiser Best Paper Award</strong>, IEEE PerCom, 2023</li>
                </ul>

                <h2>Publications</h2>
                <div><b>[C] Conference; [J] Journal; [W] Workshop; [P] Poster; [D] Demo  (*co-first authors)</b></div>
                <div><b>[CORE] <a href="https://portal.core.edu.au/conf-ranks/">CORE Conference Ranking</a>; [CCF] <a href="https://www.ccf.org.cn/Academic_Evaluation/By_category/">China Computer Federation Ranking</a></b></div>
                <div><b>The underlined <b style="border-bottom: 1px solid red; display: inline;">first author</b> is under my guidance.</b></div>
                <h3>Selected Publications</h3>
                <ul class="b" style="list-style: none; padding-left: 0;">
                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">2025</span>
                    <b style="color: #E31C79">[UIST'25]</b> PricoEye: The Eye of Primary Colors for Fast and Convenient 3D Reconstruction of Fine-grained Palmprint on Smartphones<br>
                    <u><b>Di Duan*</b></u>, Kaicheng Xiao*, Lixing He, Wei Gao, Guoliang Xing<br>
                      <b>[C]</b> <i>The 38th ACM Symposium on User Interface Software and Technology</i><br>
                      <strong>accpetance rate: 22.2%</strong>
                      <div class="labels">
                        <span class="core-label core-a">CORE A</span>
                        <span class="ccf-label ccf-a">CCF A</span>
                        <span class="community-label community-sigchi">#SIGCHI</span>
                        <span class="community-label community-siggraph">#SIGGRAPH</span>
                      </div>
                  </li>

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">    </span>
                    <b style="color: #E31C79">[SenSys'25]</b> Argus: Multi-View Egocentric Human Mesh Reconstruction Based on Stripped-Down Wearable mmWave Add-on<br>
                    <u><b>Di Duan*</b></u>, Shengzhe Lyu*, Mu Yuan, Hongfei Xue, Tianxing Li, Weitao Xu, Kaishun Wu, Guoliang Xing<br>
                      <b>[C]</b> <i>The 23rd ACM Conference on Embedded Networked Sensor Systems</i><br>
                      <strong>accpetance rate: 19.1%</strong> <strong style="color: red;">🏆 Best Paper Honorable Mention Award (5/235)</strong> <a href="award/SenSys25_BestHonorable.jpg" style="text-decoration: underline; color: black;"><strong>[link]</strong></a>
                      <div class="labels">
                        <span class="core-label core-a">CORE A*</span>
                        <span class="ccf-label ccf-b">CCF B</span>
                        <span class="highlight-label highlight-x">Best Paper Honorable Mention</span>
                        <span class="community-label community-sigbed">#SIGBED</span>
                        <span class="community-label community-sigmobile">#SIGMOBILE</span>
                      </div>
                  </li>

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">2024</span>
                    <b style="color: #E31C79">[MobiSys'24]</b> F2Key: Dynamically Converting Your Face into a Private Key Based on COTS Headphones for Reliable Voice Interaction<br>
                    <u><b>Di Duan</b></u>, Zehua Sun, Tao Ni, Shuaicheng Li, Xiaohua Jia, Weitao Xu, Tianxing Li<br>
                      <b>[C]</b> <i>The 22nd ACM International Conference on Mobile Systems, Applications, and Services</i><br>
                      <strong>accpetance rate: 16.3%</strong>
                      <div class="labels">
                        <span class="core-label core-a">CORE A</span>
                        <span class="ccf-label ccf-b">CCF B</span>
                        <span class="community-label community-sigmobile">#SIGMOBILE</span>
                      </div>
                  </li>

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">    </span>
                    <b style="color: #E31C79">[IMWUT/UbiComp'24]</b> EarSE: Bringing Robust Speech Enhancement to COTS Headphones<br>
                    <u><b>Di Duan</b></u>, Yongliang Chen, Weitao Xu, Tianxing Li<br>
                      <b>[J/C]</b> <i>ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</i>
                      <div class="labels">
                        <span class="core-label core-a">CORE A*</span>
                        <span class="ccf-label ccf-a">CCF A</span>
                        <span class="community-label community-sigmobile">#SIGMOBILE</span>
                        <span class="community-label community-sigchi">#SIGCHI</span>
                      </div>
                  </li>

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">    </span>
                    <b style="color: #E31C79">[MobileHCI'24]</b> Medusa3D: The Watchful Eye Freezing Illegitimate Users in Virtual Reality Interactions<br>
                    <b style="border-bottom: 1px solid red; display: inline;">Aochen Jiao*</b>, <u><b>Di Duan*</b></u> (*co-first authors), Weitao Xu<br>
                      <b>[C]</b> <i>The ACM International Conference on Mobile Human-Computer Interaction</i><br>
                      <strong>accpetance rate: 32.6%</strong> <strong style="color: red;">🏆 Honorable Mention Award (3/141)</strong> <a href="award/MobileHCI24_Honorable.jpg" style="text-decoration: underline; color: black;"><strong>[link]</strong></a>
                      <div class="labels">
                        <span class="core-label core-b">CORE B</span>
                        <span class="ccf-label ccf-b">CCF B</span>
                        <span class="highlight-label highlight-x">Honorable Mention Award</span>
                        <span class="community-label community-sigchi">#SIGCHI</span>
                      </div>
                  </li>

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">2023</span>
                    <b style="color: #E31C79">[PerCom'23]</b> EMGSense: A Low-Effort Self-Supervised Domain Adaptation Framework for EMG Sensing<br>
                    <u><b>Di Duan</b></u>, Huanqi Yang, Guohao Lan, Tianxing Li, Xiaohua Jia, Weitao Xu<br>
                      <b>[C]</b> <i>The 21st International Conference on Pervasive Computing and Communications</i><br>
                      <strong>accpetance rate: 16.9%</strong> <strong style="color: red;">🏆 Mark Weiser Best Paper Award (1/159)</strong> <a href="award/PerCom23_Best.jpg" style="text-decoration: underline; color: black;"><strong>[link]</strong></a>
                      <div class="labels">
                        <span class="core-label core-a">CORE A*</span>
                        <span class="ccf-label ccf-b">CCF B</span>
                        <span class="highlight-label highlight-x">Best Paper Award</span>
                        <span class="community-label community-ieee">#IEEE</span>
                      </div>
                  </li>
                </ul>

                <h3>Other Publications</h3>
                <ul class="b" style="list-style: none; padding-left: 0;">
                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">2025</span>
                    <b style="color: #E31C79">[TMC]</b> Mitigating Tail Latency for On-Device Inference with Load-Balanced Heterogeneous Models<br>
                    Mu Yuan, Lan Zhang, <u><b>Di Duan</b></u>, Liekang Zeng, Miao-Hui Song, Zichong Li, Guoliang Xing, Xiang-Yang Li<br>
                      <b>[J]</b> <i>IEEE Transactions on Mobile Computing</i>
                  </li>

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">    </span>
                    <b style="color: #E31C79">[SIGCOMM'25]</b> SCX: Stateless KV-Cache Encoding for Cloud-Scale Confidential Transformer Serving<br>
                    Mu Yuan, Lan Zhang, Liekang Zeng, Siyang Jiang, Bufang Yang, <u><b>Di Duan</b></u>, and Guoliang Xing<br>
                      <b>[C]</b> <i>The ACM SIGCOMM 2025 Conference</i>
                  </li>

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">    </span>
                    <b style="color: #E31C79">[INFOCOM'25]</b> iRadar: Synthesizing Millimeter-Waves from Wearable Inertial Inputs for Human Gesture Sensing<br>
                    Huanqi Yang, Mingda Han, Xinyue Li, <u><b>Di Duan</b></u>, Tianxing Li, and Weitao Xu<br>
                      <b>[C]</b> <i>The 2025 IEEE International Conference on Computer Communications</i>
                  </li> 

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">2024</span>
                    <b style="color: #E31C79">[TMC]</b> Scenario-Adaptive Key Establishment Scheme for LoRa-enabled IoV Communications<br>
                    Huanqi Yang, <u><b>Di Duan</b></u>, Hongbo Liu, Chengwen Luo, Yuezhong Wu, Wei Li, Albert Y. Zomaya, Linqi Song, Weitao Xu<br>
                      <b>[J]</b> <i>IEEE Transactions on Mobile Computing</i>
                  </li> 

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">    </span>
                    <b style="color: #E31C79">[MobiCom'24]</b> RF-Egg: An RF Solution for Fine-Grained Multi-Target and Multi-Task Egg Incubation Sensing<br>
                    Zehua Sun, Tao Ni, Yongliang Chen, <u><b>Di Duan</b></u>, Kai Liu, Weitao Xu<br>
                      <b>[C]</b> <i>The 30th Annual International Conference On Mobile Computing And Networking</i>
                  </li>

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">    </span>
                    <b style="color: #E31C79">[TOSN]</b> mmSign: mmWave-based Few-Shot Online Handwritten Signature Verification<br>
                    Mingda Han, Huanqi Yang, Tao Ni, <u><b>Di Duan</b></u>, Mengzhe Ruan, Yongliang Chen, Jia Zhang, Weitao Xu<br>
                      <b>[J]</b> <i>ACM Transactions on Sensor Networks</i>
                  </li>

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">    </span>
                    <b style="color: #E31C79">[CSCAIoTSys]</b> EarDA: Towards Accurate and Data-Efficient Earable Activity Sensing<br>
                    Shengzhe Lyu, Yongliang Chen, <u><b>Di Duan</b></u>, Renqi Jia, Weitao Xu<br>
                      <b>[W]</b> <i>CPS-IoT Week 2024 Workshop on Coupling of Sensing & Computing in AIoT Systems</i>
                  </li>

                  <li style="margin-bottom: 8px; position: relative; padding-left: 40px;"><span style="position: absolute; left: 0; font-weight: bold;">    </span>
                    <b style="color: #E31C79">[SenSys'24]</b> Myotrainer: Muscle-Aware Motion Analysis and Feedback System for In-Home Resistance Training<br>
                    Yuting He, Xinyan Wang, Mu Yuan, <u><b>Di Duan</b></u>, Doris S. F. Yu, Guoliang Xing, Hongkai Chen<br>
                      <b>[D]</b> <i>The 22nd ACM Conference on Embedded Networked Sensor Systems</i><br>
                      <strong style="color: red;">🏆 Best Demo Runner-up Award</strong> <a href="award/SenSys24_Demo.jpg" style="text-decoration: underline; color: black;"><strong>[link]</strong></a>
                  </li>
                </ul>

              </td>
            </tr>
          </tbody></table>

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;"  colspan="2">
              <h2>Selected Projects</h2>
            </td>
          </tr>

          <tr onmouseout="PricoEye_stop()" onmouseover="PricoEye_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; height: 100%;">
                <div class="two" id='PricoEye_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/projects/PricoEye.jpg">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/projects/PricoEye.jpg' width="160">
              </div>
              <script type="text/javascript">
                function PricoEye_start() {
                  document.getElementById('PricoEye_image').style.opacity = "1";
                }
                
                function PricoEye_stop() {
                  document.getElementById('PricoEye_image').style.opacity = "0";
                }
                PricoEye_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">[UIST'25] PricoEye: The Eye of Primary Colors for Fast and Convenient 3D Reconstruction of Fine-grained Palmprint</span>
              <br>

              <u><b>Di Duan*</b></u>,
              Kaicheng Xiao*,
              Lixing He,
              Wei Gao,
              Guoliang Xing
              <br>

              [paper] [cite] [slide] [<a href="https://www.youtube.com/watch?v=Lybnxqcmo3M">demo</a>] [<a href="https://github.com/PricoEye/PricoEye_Hardware">hardware</a>]
              <br>

              <p></p>
              <p>
                PricoEye achieves ubiquitous, portable, and ultra-low-cost 3D micro-texture reconstruction technology on smartphones. Far from being a mere patchwork, it condenses the essence of many fields and tightly couples the knowledge from mobile systems, embedded design, graphics, interaction, and form factor design.
              </p>
            </td>
          </tr>

          <tr onmouseout="Argus_stop()" onmouseover="Argus_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; height: 100%;">
                <div class="two" id='Argus_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/projects/Argus.jpg">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/projects/Argus.jpg' width="160">
              </div>
              <script type="text/javascript">
                function Argus_start() {
                  document.getElementById('Argus_image').style.opacity = "1";
                }
                
                function Argus_stop() {
                  document.getElementById('Argus_image').style.opacity = "0";
                }
                Argus_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">[<a href="https://dl.acm.org/doi/10.1145/3715014.3722045">SenSys'25</a>] Argus: Multi-View Egocentric Human Mesh Reconstruction Based on Stripped-Down Wearable mmWave Add-on</span>
              <br>

              <u><b>Di Duan*</b></u>,
              Shengzhe Lyu*,
              Mu Yuan,
              Hongfei Xue,
              Tianxing Li,
              Weitao Xu,
              Kaishun Wu,
              Guoliang Xing
              <br>

              [<a href="papers/Argus_sensys25.pdf">paper</a>] [<a href="cite/Argus.bib">cite</a>] [<a href="slide/Argus_duan_clean.pdf">slide</a>]
              <br>

              <span style="color: red;"> 🏆 Best Paper Honorable Mention Award (5/235)</span>
              <p></p>
              <p>
                Argus is the first to investigate multi-view egocentric HMR based on stripped-down mmWave radars in a multi-view configuration. Compared to conventional frontal-view solutions, it addresses several pain points, such as restricted sensing range and occlusion issues.
              </p>
            </td>
          </tr>

          <tr onmouseout="F2Key_stop()" onmouseover="F2Key_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; height: 100%;">
                <div class="two" id='F2Key_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/projects/F2Key.jpg">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/projects/F2Key.jpg' width="160">
              </div>
              <script type="text/javascript">
                function F2Key_start() {
                  document.getElementById('F2Key_image').style.opacity = "1";
                }
                
                function F2Key_stop() {
                  document.getElementById('F2Key_image').style.opacity = "0";
                }
                F2Key_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">[<a href="https://dl.acm.org/doi/10.1145/3643832.3661860">MobiSys'24</a>] F2Key: Dynamically Converting Your Face into a Private Key Based on COTS Headphones for Reliable Voice Interaction</span>
              <br>

              <u><b>Di Duan</b></u>,
              Zehua Sun,
              Tao Ni,
              Shuaicheng Li,
              Xiaohua Jia,
              Weitao Xu,
              Tianxing Li
              <br>

              [<a href="papers/F2Key_mobisys24.pdf">paper</a>] [<a href="cite/F2Key.bib">cite</a>] [<a href="slide/F2Key_duan_clean.pdf">slide</a>]
              <br>


              <p></p>
              <p>
                F2Key is the first earable physical security system based on COTS headphones that enables several security-related applications, such as artifacts anti-counterfeiting, speech manipulation/deepfake detection, defence against voiceprint-based attacks.
              </p>
            </td>
          </tr>
          
          <tr onmouseout="EarSE_stop()" onmouseover="EarSE_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; height: 100%;">
                <div class="two" id='EarSE_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/projects/EarSE.jpg">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/projects/EarSE.jpg' width="160">
              </div>
              <script type="text/javascript">
                function EarSE_start() {
                  document.getElementById('EarSE_image').style.opacity = "1";
                }
                
                function EarSE_stop() {
                  document.getElementById('EarSE_image').style.opacity = "0";
                }
                EarSE_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">[<a href="https://doi.org/10.1145/3631447">IMWUT/UbiComp'24</a>] EarSE: Bringing Robust Speech Enhancement to COTS Headphones</span>
              <br>

              <u><b>Di Duan</b></u>,
              Yongliang Chen,
              Weitao Xu,
              Tianxing Li
              <br>

              [<a href="papers/EarSE_imwut24.pdf">paper</a>] [<a href="cite/EarSE.bib">cite</a>] [<a href="slide/EarSE_duan_clean.pdf">slide</a>]
              <br>


              <p></p>
              <p>
                EarSE is a pioneer in exploring boom mic sensing, for the first time utilizing COTS headphones and boom/modular microphones to establish a stable acoustic sensing field across the user's face. It filters out ambient noise to obtain the wearer's clean speech in a multi-modality manner.
              </p>
            </td>
          </tr>

          <tr onmouseout="EMGSense_stop()" onmouseover="EMGSense_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; height: 100%;">
                <div class="two" id='EMGSense_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/projects/EMGSense.jpg">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/projects/EMGSense.jpg' width="160">
              </div>
              <script type="text/javascript">
                function EMGSense_start() {
                  document.getElementById('EMGSense_image').style.opacity = "1";
                }
                
                function EMGSense_stop() {
                  document.getElementById('EMGSense_image').style.opacity = "0";
                }
                EMGSense_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">[<a href="https://doi.org/10.1109/PERCOM56429.2023.10099164">PerCom'23</a>] EMGSense: A Low-Effort Self-Supervised Domain Adaptation Framework for EMG Sensing</span>
              <br>

              <u><b>Di Duan</b></u>,
              Huanqi Yang,
              Guohao Lan,
              Tianxing Li,
              Xiaohua Jia,
              Weitao Xu
              <br>

              [<a href="papers/EMGSense_percom23.pdf">paper</a>] [<a href="cite/EMGSense.bib">cite</a>]
              <br>

              <span style="color: red;"> 🏆 Mark Weiser Best Paper Award (1/159)</span>
              <p></p>
              <p>
                EMGSense framework addresses the biological heterogeneity problem in cross-domain deployment of EMG-based applications in a low-effort manner, combining domain adaptation and self-supervised learning techniques. 
              </p>
            </td>
          </tr>
          </tbody></table>

    <table style="width: 100%; margin: 0 auto; border: none; padding: 20px;">
      <tbody>
        <tr>
          <td>
            <h2>Professional Services</h2>
            <ul>
              <li><strong> Organizing Committee (OC): </strong>BodySys Publicity Chair (MobiSys'24 Workshop)</li>
              <li><strong> Artifact Evaluation Committee (AEC): </strong>MobiCom 2025, MobiSys 2024</li>
              <li><strong> Technical Program Committee (TPC): </strong>ICPADS 2025, ICPADS 2024, Chinese CHI 2024, SenSys 2025 (Demo)</li>
              <li><strong> Conference Review: </strong>
                <br><strong> [2025] </strong>UbiComp'25, CHI'25, MobiCom'25, SIGCOMM'25
                <br><strong> [2024] </strong>SenSys'24, IPSN'24, IOTDI'24, ICDCS'24, DCOSS-IoT'24
                <br><strong> [2023] </strong>IPSN'23</li>
              <li><strong> Journal Review: </strong>IMWUT, TMC (IEEE Trans), TIOT (ACM Trans), HEALTH (ACM Trans), Ad Hoc Networks</li>     
            </ul>
          </td>
        </tr>
      </tbody>
    </table>

    <table style="width: 100%; margin: 0 auto; border: none; padding: 20px;">
      <tbody>
        <tr>
          <td>
            <h2>Teaching Experience</h2>
            <ul>
              <li><strong>[IERG6200] Advanced Topics in Computer Networks</strong>, Course Manager, 2024R1-IERG6200, CUHK</li>
              <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2023/24 Semester B, CityU</li>
              <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Tutor, 2023/24 Semester A, CityU</li>
              <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2022/23 Semester B, CityU</li>
              <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2022/23 Semester A, CityU</li>
              <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Tutor, 2021/22 Semester B, CityU</li>
              <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2021/22 Semester A, CityU</li>
              <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2020/21 Semester B, CityU</li>
              <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2020/21 Semester A, CityU</li>
            </ul>
          </td>
        </tr>
      </tbody>
    </table>
        
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:center;font-size:small;">Last updated July 2025</p>
          <p style="text-align:center;font-size:small;">Design and source code from <a href="https://jonbarron.info/">Jon Barron's website</a>.</p>
        </td>
      </tr>
    </tbody></table>

    <div style="width:20%;margin:0 auto;max-width:200px;">
      <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=WyIPbY8zGj6I8ddviHOVm__3pmqlrUlyZxPY-gV5GQU"></script>
    </div><table>
    </table>
  </body>
</html>
