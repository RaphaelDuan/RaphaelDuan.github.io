<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Di Duan</title>

    <meta name="author" content="Di Duan">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Di Duan
                </p>
                <p>I‚Äôm a <del>first</del> <del>second</del> <del>third</del> <strong>final year</strong> Ph.D. candidate at the <a href="https://www.cs.cityu.edu.hk/">Department of Computer Science</a> at <a href="https://www.cityu.edu.hk/">City University of Hong Kong</a> (supervised by Dr. <a href="https://www.weitaoxu.com/">Weitao Xu</a>, co-supervised by Prof. <a href="https://www.cs.cityu.edu.hk/~jia/">Xiaohua Jia</a>), I also work closely with Dr. <a href="https://www.cse.msu.edu/~litianx2/">Tianxing Li</a>. Before that, I obtained my M.Sc. degree from the Hong Kong University of Science and Technology (<a href="https://hkust.edu.hk/">HKUST</a>) in 2019, and my B.E. degree from the Harbin Engineering University (<a href="http://www.hrbeu.edu.cn/">HEU</a>) in 2018, respectively.
                </p>
                <p>My research lies at the intersection of Mobile Computing and Human-Computer Interaction ‚Äî with a special focus on system-enabled novel applications, wearable sensing, and deep learning. I received the <a href="https://www.percom.org/">IEEE PerCom 2023</a> Mark Weiser Best Paper Award.
                </p>
                <p>
                  <strong style="color: red;">I'm actively seeking postdoctoral positions</strong> with a focus on <strong>system-enabled novel applications</strong> and <strong>human-computer interaction</strong>.
                </p>
                <p>
                  <strong>Email:</strong> duandiacademic [AT] gmail [DOT] com
                </p>
                <p style="text-align:center">
                  <a href="mailto:duandiacademic@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/DiDuan-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=BRFlCnUAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/di-duan-543065170/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/pictures/avatar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/pictures/avatar.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <ul>
                  <li>[2024/03] I'm serving as the Publicity Chair of BobySys Workshop (MobiSys 2024). Please refer to our <a href="https://www.eventcreate.com/e/bodysys24">official website</a>. </li>
                  <li>[2024/03] Our paper F2Key is conditionally accepted by MobiSys'24. I will present this paper in Tokyo in Jun. 2024.</li>
                  <li>[2024/02] One co-authored paper RF-Egg is accepted by MobiCom'24.</li>
                  <li>[2023/10] Our paper EarSE is accepted by IMWUT/UbiComp'24. I will present this paper in Melbourne in Oct. 2024.</li>
                  <li>[2023/03] Receive Monetary Award of 300 USD from Elsevier.</li>
                  <li>[2023/03] Our paper EMGSense receives the <span class="highlight">Mark Weiser Best Paper Award</span> at PerCom 2023.</li>
                </ul>

                <h2>Publications</h2>
                <ul class="b">
                  <li style="margin-bottom: 8px;">EarSE: Bringing Robust Speech Enhancement to COTS Headphones<br>
                    <u><b>Di Duan</b></u>, Yongliang Chen, Weitao Xu, Tianxing Li<br>
                      <i>ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (<b>IMWUT/UbiComp 2024</b>)</i>
                  </li>

                  <li style="margin-bottom: 8px;">EMGSense: A Low-Effort Self-Supervised Domain Adaptation Framework for EMG Sensing<br>
                    <u><b>Di Duan</b></u>, Huanqi Yang, Guohao Lan, Tianxing Li, Xiaohua Jia, Weitao Xu<br>
                      <i>The 21st International Conference on Pervasive Computing and Communications (<b>PerCom 2023</b>)</i><br>
                      <strong>accpetance rate: 16.9%</strong> <strong style="color: red;">üèÜ Mark Weiser Best Paper Award (1/159)</strong> 
                  </li>

                  <li style="margin-bottom: 8px;">RF-Egg: An RF Solution for Fine-Grained Multi-Target and Multi-Task Egg Incubation Sensing<br>
                    Zehua Sun, Tao Ni, Yongliang Chen, <u><b>Di Duan</b></u>, Kai Liu, Weitao Xu<br>
                      <i>The 30th Annual International Conference On Mobile Computing And Networking (<b>MobiCom 2024</b>)</i>
                  </li>

                  <li style="margin-bottom: 8px;">mmSign: mmWave-based Few-Shot Online Handwritten Signature Verification<br>
                    Mingda Han, Huanqi Yang, Tao Ni, <u><b>Di Duan</b></u>, Mengzhe Ruan, Yongliang Chen, Jia Zhang, Weitao Xu<br>
                      <i>ACM Transactions on Sensor Networks (<b>TOSN</b>)</i>
                  </li>
                </ul>

              </td>
            </tr>
          </tbody></table>

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;"  colspan="2">
              <h2>Selected Projects</h2>
            </td>
          </tr>
          
          <tr onmouseout="EarSE_stop()" onmouseover="EarSE_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; height: 100%;">
                <div class="two" id='EarSE_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/projects/EarSE.jpg">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/projects/EarSE.jpg' width="160">
              </div>
              <script type="text/javascript">
                function EarSE_start() {
                  document.getElementById('EarSE_image').style.opacity = "1";
                }
                
                function EarSE_stop() {
                  document.getElementById('EarSE_image').style.opacity = "0";
                }
                EarSE_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">[<a href="https://doi.org/10.1145/3631447">IMWUT/UbiComp'24</a>] EarSE: Bringing Robust Speech Enhancement to COTS Headphones</span>
              <br>

              <u><b>Di Duan</b></u>,
              Yongliang Chen,
              Weitao Xu,
              Tianxing Li
              <br>

              [<a href="papers/EarSE_imwut24.pdf">paper</a>] [<a href="cite/EarSE.bib">cite</a>]
              <br>


              <p></p>
              <p>
                EarSE is a pioneer in exploring boom mic sensing, for the first time utilizing COTS headphones and boom/modular microphones to establish a stable acoustic sensing field across the user's face. It filters out ambient noise to obtain the wearer's clean speech in a multi-modality manner.
              </p>
            </td>
          </tr>

          <tr onmouseout="EMGSense_stop()" onmouseover="EMGSense_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; height: 100%;">
                <div class="two" id='EMGSense_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/projects/EMGSense.jpg">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/projects/EMGSense.jpg' width="160">
              </div>
              <script type="text/javascript">
                function EMGSense_start() {
                  document.getElementById('EMGSense_image').style.opacity = "1";
                }
                
                function EMGSense_stop() {
                  document.getElementById('EMGSense_image').style.opacity = "0";
                }
                EMGSense_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">[<a href="https://doi.org/10.1109/PERCOM56429.2023.10099164">PerCom'23</a>] EMGSense: A Low-Effort Self-Supervised Domain Adaptation Framework for EMG Sensing</span>
              <br>

              <u><b>Di Duan</b></u>,
              Huanqi Yang,
              Guohao Lan,
              Tianxing Li,
              Xiaohua Jia,
              Weitao Xu
              <br>

              [<a href="papers/EMGSense_percom23.pdf">paper</a>] [<a href="cite/EMGSense.bib">cite</a>]
              <br>

              <font color="red"> üèÜ Mark Weiser Best Paper Award (1/159)</font>
              <p></p>
              <p>
                EMGSense framework addresses the biological heterogeneity problem in cross-domain deployment of EMG-based applications in a low-effort manner, combining domain adaptation and self-supervised learning techniques. 
              </p>
            </td>
          </tr>
          </tbody></table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
      <tr>
        <td>
          <h2>Professional Services</h2>
          <ul>
            <li><strong> 2024 MobiSys-BodySys Workshop: Publicity Chair</strong> </li>
            <li><strong> 2024 Conference Review</strong> (invited review): IPSN, IOTDI, ICDCS, DCOSS-IoT</li>
            <li><strong> 2024 Journal Review</strong> (invited review): Ad Hoc Networks</li>
            <li><strong> 2023 Conference Review</strong> (invited review): IPSN</li>          
          </ul>
        </td>
      </tr>
    </tbody></table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
      <tr>
        <td>
          <h2>Teaching Experience</h2>
          <ul>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2023/24 Semester B, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Tutor, 2023/24 Semester A, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2022/23 Semester B, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2022/23 Semester A, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Tutor, 2021/22 Semester B, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2021/22 Semester A, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2020/21 Semester B, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2020/21 Semester A, CityU</li>
          </ul>
        </td>
      </tr>
    </tbody></table>
        
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:center;font-size:small;">Last updated Mar. 2024</p>
          <p style="text-align:center;font-size:small;">Design and source code from <a href="https://jonbarron.info/">Jon Barron's website</a>.</p>
        </td>
      </tr>
    </tbody></table>

    <div style="width:20%;margin:0 auto;">
      <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=WyIPbY8zGj6I8ddviHOVm__3pmqlrUlyZxPY-gV5GQU"></script>
    </div><table>
    </table>

        </td>
      </tr>
    </table>
  </body>
</html>
