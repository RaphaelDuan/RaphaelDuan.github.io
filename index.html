<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Di Duan, Ph.D.</title>

    <meta name="author" content="Di Duan">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Di Duan
                </p>
                <p>I obtained my Ph.D. degree from the <a href="https://www.cs.cityu.edu.hk/">Department of Computer Science</a> at <a href="https://www.cityu.edu.hk/">City University of Hong Kong</a>, supervised by Dr. <a href="https://www.weitaoxu.com/">Weitao Xu</a> (IEEE Senior Member) and co-supervised by Prof. <a href="https://www.cs.cityu.edu.hk/~jia/">Xiaohua Jia</a> (IEEE Fellow), I also work closely with Dr. <a href="https://www.cse.msu.edu/~litianx2/">Tianxing Li</a>. Before that, I obtained my M.Sc. degree from the Hong Kong University of Science and Technology (<a href="https://hkust.edu.hk/">HKUST</a>) in 2019, and my B.E. degree from the Harbin Engineering University (<a href="http://www.hrbeu.edu.cn/">HEU</a>) in 2018, respectively.
                </p>
                <p>My research lies at the intersection of Mobile Computing and Human-Computer Interaction ‚Äî with a special focus on system-enabled novel applications, wearable sensing, and deep learning. I received the <a href="https://www.percom.org/">IEEE PerCom 2023</a> Mark Weiser Best Paper Award.
                </p>
                <p>
                  I'm focusing on <strong style="color: red;">system-enabled novel applications</strong> and <strong style="color: red;">human-computer interaction</strong>.
                </p>
                <p>
                  <strong>Email:</strong> duandiacademic [AT] gmail [DOT] com
                </p>
                <p style="text-align:center">
                  <a href="mailto:duandiacademic@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/DiDuan-CV.pdf">CV</a> <span style="font-size: smaller;">(Updated: 2024-07)</span> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=BRFlCnUAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/di-duan-543065170/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/pictures/avatar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/pictures/avatar.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <ul>
                  <li>[2024/07] I will join the <a href="https://aiot.ie.cuhk.edu.hk">CUHK AIoT Lab</a> as a <b>Post-doctoral Research Fellow</b>, working directly with Prof. <a href="https://staff.ie.cuhk.edu.hk/~glxing/">Guoliang Xing</a>.</li>
                  <li>[2024/06] <span style="color: red; font-weight: bold;">News</span>‚ùóÔ∏è I'm pleased to share with everyone that I have just passed my Ph.D. defense.</li>
                  <li>[2024/04] One co-first authored paper Medusa3D is conditionally accepted (with minor revision) by MobileHCI'24.</li>
                  <li>[2024/03] I'm serving as the Publicity Chair of BobySys Workshop (MobiSys 2024). Please refer to our <a href="https://www.eventcreate.com/e/bodysys24">official website</a>. </li>
                  <li>[2024/03] Our paper F2Key is accepted by MobiSys'24. I will present this paper in Tokyo in Jun. 2024.</li>
                  <li>[2024/02] One co-authored paper RF-Egg is accepted by MobiCom'24.</li>
                  <li>[2023/10] Our paper EarSE is accepted by IMWUT/UbiComp'24. I will present this paper in Melbourne in Oct. 2024.</li>
                  <li>[2023/03] Receive Monetary Award of 300 USD from Elsevier.</li>
                  <li>[2023/03] Our paper EMGSense receives the <span class="highlight">Mark Weiser Best Paper Award</span> at PerCom 2023.</li>
                </ul>

                <h2>Publications</h2>
                <div><b>[C] Conference [J] Journal [W] Workshop [P] Poster  (*co-first authors)</b></div>
                <div><b>The underlined <b style="border-bottom: 1px solid red; display: inline;">first author</b> is under my guidance.</b></div>
                <h3>Main Publications</h3>
                <ul class="b">
                  <li style="margin-bottom: 8px;"><b>[C]</b> F2Key: Dynamically Converting Your Face into a Private Key Based on COTS Headphones for Reliable Voice Interaction<br>
                    <u><b>Di Duan</b></u>, Zehua Sun, Tao Ni, Shuaicheng Li, Xiaohua Jia, Weitao Xu, Tianxing Li<br>
                      <b>[MobiSys'24]</b> <i>The 22nd ACM International Conference on Mobile Systems, Applications, and Services</i>
                      <div class="labels">
                        <span class="ccf-label ccf-b">CCF B</span>
                        <span class="core-label core-a">CORE A</span>
                      </div>
                  </li>

                  <li style="margin-bottom: 8px;"><b>[C]</b> EarSE: Bringing Robust Speech Enhancement to COTS Headphones<br>
                    <u><b>Di Duan</b></u>, Yongliang Chen, Weitao Xu, Tianxing Li<br>
                      <b>[IMWUT/UbiComp'24]</b> <i>ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</i>
                      <div class="labels">
                        <span class="ccf-label ccf-a">CCF A</span>
                        <span class="core-label core-a">CORE A*</span>
                      </div>
                  </li>

                  <li style="margin-bottom: 8px;"><b>[C]</b> EMGSense: A Low-Effort Self-Supervised Domain Adaptation Framework for EMG Sensing<br>
                    <u><b>Di Duan</b></u>, Huanqi Yang, Guohao Lan, Tianxing Li, Xiaohua Jia, Weitao Xu<br>
                      <b>[PerCom'23]</b> <i>The 21st International Conference on Pervasive Computing and Communications</i><br>
                      <strong>accpetance rate: 16.9%</strong> <strong style="color: red;">üèÜ Mark Weiser Best Paper Award (1/159)</strong> 
                      <div class="labels">
                        <span class="ccf-label ccf-b">CCF B</span>
                        <span class="core-label core-a">CORE A*</span>
                      </div>
                  </li>

                  <li style="margin-bottom: 8px;"><b>[C]</b> Medusa3D: The Watchful Eye Freezing Illegitimate Users in Virtual Reality Interactions<br>
                    <b style="border-bottom: 1px solid red; display: inline;">Aochen Jiao*</b>, <u><b>Di Duan*</b></u> (*co-first authors), Weitao Xu<br>
                      <b>[MobileHCI'24]</b> <i>The ACM International Conference on Mobile Human-Computer Interaction</i><br>
                      <div class="labels">
                        <span class="ccf-label ccf-b">CCF B</span>
                        <span class="core-label core-b">CORE B</span>
                      </div>
                  </li>
                </ul>

                <h3>Other Publications</h3>
                <ul class="b">
                  <li style="margin-bottom: 8px;"><b>[J]</b> Scenario-Adaptive Key Establishment Scheme for LoRa-enabled IoV Communications<br>
                    Huanqi Yang, <u><b>Di Duan</b></u>, Hongbo Liu, Chengwen Luo, Yuezhong Wu, Wei Li, Albert Y. Zomaya, Linqi Song, Weitao Xu<br>
                      <b>[TMC]</b> <i>IEEE Transactions on Mobile Computing</i>
                  </li> 

                  <li style="margin-bottom: 8px;"><b>[C]</b> RF-Egg: An RF Solution for Fine-Grained Multi-Target and Multi-Task Egg Incubation Sensing<br>
                    Zehua Sun, Tao Ni, Yongliang Chen, <u><b>Di Duan</b></u>, Kai Liu, Weitao Xu<br>
                      <b>[MobiCom'24]</b> <i>The 30th Annual International Conference On Mobile Computing And Networking</i>
                  </li>

                  <li style="margin-bottom: 8px;"><b>[J]</b> mmSign: mmWave-based Few-Shot Online Handwritten Signature Verification<br>
                    Mingda Han, Huanqi Yang, Tao Ni, <u><b>Di Duan</b></u>, Mengzhe Ruan, Yongliang Chen, Jia Zhang, Weitao Xu<br>
                      <b>[TOSN]</b> <i>ACM Transactions on Sensor Networks</i>
                  </li>

                  <li style="margin-bottom: 8px;"><b>[W]</b> EarDA: Towards Accurate and Data-Efficient Earable Activity Sensing<br>
                    Shengzhe Lyu, Yongliang Chen, <u><b>Di Duan</b></u>, Renqi Jia, Weitao Xu<br>
                      <b>[CSCAIoTSys]</b> <i>CPS-IoT Week 2024 Workshop on Coupling of Sensing & Computing in AIoT Systems</i>
                  </li>
                </ul>

              </td>
            </tr>
          </tbody></table>

          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;"  colspan="2">
              <h2>Selected Projects</h2>
            </td>
          </tr>

          <tr onmouseout="F2Key_stop()" onmouseover="F2Key_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; height: 100%;">
                <div class="two" id='F2Key_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/projects/F2Key.jpg">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/projects/F2Key.jpg' width="160">
              </div>
              <script type="text/javascript">
                function F2Key_start() {
                  document.getElementById('F2Key_image').style.opacity = "1";
                }
                
                function F2Key_stop() {
                  document.getElementById('F2Key_image').style.opacity = "0";
                }
                F2Key_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">[MobiSys'24] F2Key: Dynamically Converting Your Face into a Private Key Based on COTS Headphones for Reliable Voice Interaction</span>
              <br>

              <u><b>Di Duan</b></u>,
              Zehua Sun,
              Tao Ni,
              Shuaicheng Li,
              Xiaohua Jia,
              Weitao Xu,
              Tianxing Li
              <br>

              [<a href="papers/F2Key_mobisys24.pdf">paper</a>] [<a href="cite/F2Key.bib">cite</a>] [<a href="slide/F2Key_duan_clean.pdf">slide</a>]
              <br>


              <p></p>
              <p>
                F2Key is the first earable physical security system based on COTS headphones that enables several security-related applications, such as artifacts anti-counterfeiting, speech manipulation/deepfake detection, defence against voiceprint-based attacks.
              </p>
            </td>
          </tr>
          
          <tr onmouseout="EarSE_stop()" onmouseover="EarSE_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; height: 100%;">
                <div class="two" id='EarSE_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/projects/EarSE.jpg">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/projects/EarSE.jpg' width="160">
              </div>
              <script type="text/javascript">
                function EarSE_start() {
                  document.getElementById('EarSE_image').style.opacity = "1";
                }
                
                function EarSE_stop() {
                  document.getElementById('EarSE_image').style.opacity = "0";
                }
                EarSE_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">[<a href="https://doi.org/10.1145/3631447">IMWUT/UbiComp'24</a>] EarSE: Bringing Robust Speech Enhancement to COTS Headphones</span>
              <br>

              <u><b>Di Duan</b></u>,
              Yongliang Chen,
              Weitao Xu,
              Tianxing Li
              <br>

              [<a href="papers/EarSE_imwut24.pdf">paper</a>] [<a href="cite/EarSE.bib">cite</a>]
              <br>


              <p></p>
              <p>
                EarSE is a pioneer in exploring boom mic sensing, for the first time utilizing COTS headphones and boom/modular microphones to establish a stable acoustic sensing field across the user's face. It filters out ambient noise to obtain the wearer's clean speech in a multi-modality manner.
              </p>
            </td>
          </tr>

          <tr onmouseout="EMGSense_stop()" onmouseover="EMGSense_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one" style="display: flex; align-items: center; height: 100%;">
                <div class="two" id='EMGSense_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/projects/EMGSense.jpg">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/projects/EMGSense.jpg' width="160">
              </div>
              <script type="text/javascript">
                function EMGSense_start() {
                  document.getElementById('EMGSense_image').style.opacity = "1";
                }
                
                function EMGSense_stop() {
                  document.getElementById('EMGSense_image').style.opacity = "0";
                }
                EMGSense_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">[<a href="https://doi.org/10.1109/PERCOM56429.2023.10099164">PerCom'23</a>] EMGSense: A Low-Effort Self-Supervised Domain Adaptation Framework for EMG Sensing</span>
              <br>

              <u><b>Di Duan</b></u>,
              Huanqi Yang,
              Guohao Lan,
              Tianxing Li,
              Xiaohua Jia,
              Weitao Xu
              <br>

              [<a href="papers/EMGSense_percom23.pdf">paper</a>] [<a href="cite/EMGSense.bib">cite</a>]
              <br>

              <font color="red"> üèÜ Mark Weiser Best Paper Award (1/159)</font>
              <p></p>
              <p>
                EMGSense framework addresses the biological heterogeneity problem in cross-domain deployment of EMG-based applications in a low-effort manner, combining domain adaptation and self-supervised learning techniques. 
              </p>
            </td>
          </tr>
          </tbody></table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
      <tr>
        <td>
          <h2>Professional Services</h2>
          <ul>
            <li><strong> 2024 MobiSys-BodySys Workshop: Publicity Chair</strong> </li>
            <li><strong> Artifact Evaluation Committee</strong>: MobiSys 2024</li>
            <li><strong> Conference Review</strong> (invited review): IPSN 2024, IOTDI 2024, ICDCS 2024, DCOSS-IoT 2024, IPSN 2023</li>
            <li><strong> Journal Review</strong> (invited review): Transactions on Mobile Computing (TMC), Ad Hoc Networks</li>     
          </ul>
        </td>
      </tr>
    </tbody></table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
      <tr>
        <td>
          <h2>Teaching Experience</h2>
          <ul>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2023/24 Semester B, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Tutor, 2023/24 Semester A, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2022/23 Semester B, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2022/23 Semester A, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Tutor, 2021/22 Semester B, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2021/22 Semester A, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2020/21 Semester B, CityU</li>
            <li><strong>[CS1302] Introduction to Computer Programming (Python)</strong>, Teaching Assistant, 2020/21 Semester A, CityU</li>
          </ul>
        </td>
      </tr>
    </tbody></table>
        
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:center;font-size:small;">Last updated Jun. 2024</p>
          <p style="text-align:center;font-size:small;">Design and source code from <a href="https://jonbarron.info/">Jon Barron's website</a>.</p>
        </td>
      </tr>
    </tbody></table>

    <div style="width:20%;margin:0 auto;max-width:200px;">
      <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=WyIPbY8zGj6I8ddviHOVm__3pmqlrUlyZxPY-gV5GQU"></script>
    </div><table>
    </table>
  </body>
</html>
